---
title: "Documentation"
format: html
editor: visual
---

# **Quarterly Data Features**

You can obtain quarterly data files from the Food and Drug Administration Adverse Event Reporting System by visiting the website [**https://fis.fda.gov/extensions/FPD-QDE-FAERS/FPD-QDE-FAERS.html**](https://fis.fda.gov/extensions/FPD-QDE-FAERS/FPD-QDE-FAERS.html). These files are available in both ASCII and XML formats. For our work, we focus on the ASCII files, which use the "\$" character to separate different fields. It's important to note that neither of these file formats includes all possible data fields. If you need access to all the information, you can make a request through the Freedom of Information Act. When working with the ASCII files, you should refer to the "CASE" field for LAERS ASCII files and the "CASEID" field for FAERS ASCII files.

The data is organized into quarters, representing the four three-month periods of the year: January-March, April-June, July-September, and October-December. The first quarter of the FAERS data is January-March 2004. It's essential to understand that the quarter refers to the date the report was received by the FDA. Therefore, the FAERS can collect reports about events that occurred before 2004 as well.

Each quarter is further divided into several datasets that contain specific information:

-   DEMO: Demographic and administrative information.

-   DRUG: Medical products and posology.

-   REAC: Adverse events.

-   OUTC: Outcomes.

-   RPSR: Report sources.

-   THER: Temporal information about therapies.

-   INDI: Indications.

The name of each file follows a specific format: \<file-descriptor\>yyQq. Here, \<file-descriptor\> represents the four-letter dataset name mentioned earlier, 'yy' indicates a two-digit identifier for the year, 'Q' is the letter Q, and 'q' is a one-digit identifier for the specific quarter. For instance, DEMO12Q4 represents the demographic file for the fourth quarter of 2012.

Each extract includes a set of seven ASCII data files that cover the entire quarter. Starting from 19Q1, each quarter also includes a DELETED file, which contains a list of report identities that should be excluded from the database (the so-called nullified reports). The decision to exclude these reports is made by the FDA or Manufacturers for various reasons, with the aim of aligning the Quarterly Data Extract (QDE) with the public dashboard.

Over time, the data fields have been updated. The conversion from the Legacy Adverse Event Reporting System to the new FDA Adverse Event Reporting System (FAERS) took place in September 2012 (12Q3). To prevent the loss of reports, the first extract of FAERS also includes reports from July 2012.

Data fields have been updated through time, and September 2012 (12Q3) marks the conversion from the Legacy Adverse Event Reporting System to the newÂ FDA Adverse Event Reporting System (FAERS). To avoid the loss of reports, the first extract also includes reports from July 2012.

In the previous LAERS database, the data was based on Individual Safety Reports (ISR), where each ISR represented a separate version of a case (e.g., Initial, Follow-up 1, Follow-up 2, and so on). In contrast, the new FAERS database is case-based, where each case can have one or more versions starting from version 1. Intermediate versions may be missing if multiple updates were reported during the same quarter.

Lastly, it's important to note that the LAERS data was compiled in uppercase, while the FAERS data is in mixed case.

Further details about data features are provided in the following paragraphs.

![](images/FAERS_flowchart-01.png)

\
The Entity Relationship Diagram (ERD) of the FAERS illustrates the relationships between different datasets.

-   The "primaryid" attribute is used to identify a specific version of a caseid. It serves as the primary key in several datasets.

-   DEMO dataset: In the DEMO dataset, there should be only one "primaryid" value, but there can be multiple "caseid"s associated with that "primaryid".

-   REAC, OUTC, RPSR, and DRUG datasets: The "primaryid" attribute serves as the primary key in these datasets. Each dataset can have multiple rows with the same "primaryid" value, indicating multiple reactions, outcomes, report sources, or drugs associated with a particular case.

-   THER and INDI datasets: The combination of "primaryid" and "drug_seq" attributes is used to join these datasets with the DRUG dataset. The "primaryid" and "drug_seq" together act as a composite key to establish the relationship between the THER and INDI datasets with the DRUG dataset. This relationship implies that multiple therapies or indications can be associated with a specific drug for a particular case.

# **Cleaning pipeline**

In the following steps, we outline the procedure for cleaning the data. It's important to note that you don't need to understand every line of code to obtain a cleaned database. You can simply run the provided script or use the already cleaned database. However, it is crucial to read the accompanying text to comprehend how the pre-processing steps impact the subsequent analyses and interpretation. In the case you want to run the script, please include the script, along with the project, in a folder named "DIANA".

Please ensure you have an internet connection as the script will download the necessary tools and FAERS quarterly data from the internet.

## 1. Set up

### a. Import Tools

To perform the analyses, certain tools are required. R, an open-source software, enables the utilization of packages containing algorithms designed for specific operations. In the process of cleaning the FAERS data, the following libraries are utilized:

-   pacman: package to help importing other packages

-   tidyverse: A collection of packages (including ggplot2, dplyr, tidyr, and others) that provide a consistent and powerful set of tools for data manipulation, exploration, and visualization.

-   data.table: A package that extends the functionality of data frames in R, providing a fast and efficient way to manipulate large datasets.

-   janitor: A package that offers functions to clean and tidy messy datasets, facilitating data cleaning tasks.

-   foreach: A package that provides a looping construct for iterating over elements in parallel or sequentially. It is often used in combination with other packages for parallel computing, shortening preprocessing time.

-   xml2: A package for working with XML files, allowing you to parse, manipulate, and extract information from XML data.

-   rvest: A package that enables web scraping in R by providing functions to extract information from HTML web pages.

![](images/Diagram.drawio%20(1).svg)

```{r eval=FALSE}

## Set up packages-------------------------------------------------------------

if (!require("pacman")) install.packages("pacman")
pacman::p_load("tidyverse","data.table","janitor","foreach","xml2","rvest")
```

### b. Download FAERS

We have provided a script that facilitates the automatic download of FAERS quarterly data in ASCII file format from the FDA website. The duration of this step can vary depending on factors such as internet speed and memory capacity. In our tests, the download process took between 1 hour and 25 minutes (with a download speed of 74.4 Mbps) to 2 hours (with a download speed of 8.68 Mbps). However, it is important to note that the actual duration may be shorter or longer, as it can be influenced by individual circumstances.

![](images/Diagram.drawio%20(2).svg)

```{r eval = FALSE}
## Download FAERS--------------------------------------------------------------
options(timeout=500)#increase if it times out because of low wifi power
FAERS_url <- "https://fis.fda.gov/extensions/FPD-QDE-FAERS/FPD-QDE-FAERS.html"
pg <- read_html(FAERS_url)
links_to_QD <- html_attr(html_nodes(pg, "a"), "href")
links_to_QD <- links_to_QD[grepl(".zip",links_to_QD) & grepl("ascii", links_to_QD)]
dir.create("Raw_FAERS_QD")
for (file in links_to_QD){
  zip_name <- file.path("Raw_FAERS_QD", basename(file))
  download.file(file, zip_name)
  folder_name <- gsub(".zip","",zip_name)
  dir.create(folder_name)
  unzip(zip_name,exdir=folder_name)
  file.remove(zip_name)
}
file.rename("Raw_FAERS_QD//faers_ascii_2018q1/ascii/DEMO18Q1_new.txt",
            "Raw_FAERS_QD//faers_ascii_2018q1/ascii/DEMO18Q1.txt")

```

### c. Better Storage

Each TXT ASCII file in the dataset has entries separated by a \$ sign. To optimize memory usage, we have imported and saved these datasets in the RDS format. This format reduces the amount of memory required and improves the speed of reading and writing files.

During the initial import, we encountered some issues with \# signs, single quotes ('), and apostrophes, which caused conflicts during the import process. Additionally, we discovered inconsistencies in the number of fields between the header lines and data lines. This inconsistency was caused by a missing \$ sign at the end of the header line, leading to improper data reading.

Furthermore, we manually integrated the files to address the following errors:

In DRUG2011Q2, there was a missing newline at line 322966.

In DRUG2011Q3, there was a missing newline at line 247895.

In DRUG2011Q4, there was a missing newline at line 446737.

With the script, we automatically resolve these errors and conflicts, allowing for a smoother data processing experience.

![](images/Diagram.drawio%20(3).svg)

```{r eval = FALSE}
##Improve storage--------------------------------------------------------------
faers_list <- list.files(path="Raw_FAERS_QD/",
                         recursive=T,pattern=".TXT",
                         ignore.case = T, full.names = T)
faers_list <- faers_list[!grepl("STAT|SIZE",faers_list)]
dir.create("Clean Data")
write.csv2(faers_list, "Clean Data/faers_list.csv")

## correct for missing newlines
correct_problematic_file <- function(file_path, old_line) {
  lines <- readLines(file(file_path,open = "r"))
  lines <- unlist(strsplit(gsub(old_line,
                                gsub("([0-9]+)$","SePaRaToR\\1",old_line),
                                lines,fixed=T),
                           "SePaRaToR"))
  writeLines(lines, con = file_path)
}

correct_problematic_file("Raw_FAERS_QD//aers_ascii_2011q2/ascii/DRUG11Q2.txt",
                         "\\$\\$\\$\\$\\$\\$7475791")
correct_problematic_file("Raw_FAERS_QD//aers_ascii_2011q3/ascii/DRUG11Q3.txt",
                         "\\$\\$\\$\\$\\$\\$7652730")
correct_problematic_file("Raw_FAERS_QD//aers_ascii_2011q4/ascii/DRUG11Q4.txt",
                         "021487\\$7941354")

## store to rds
store_to_rds <-  function(f){
  name <- gsub(".TXT",".rds",f, ignore.case = T)
  print (name)
  cn<- unlist(strsplit(readLines(file(f),n=1),split = "\\$"))
  x <- read.table(f,skip=1,sep="$", comment.char = "",quote="",row.names = NULL)
  colnames(x) <- cn
  saveRDS(x,file=name)
  closeAllConnections()
}

invisible(lapply(faers_list, store_to_rds))
```

## 2. Merge quarters

We initiated the process of merging quarters within each dataframe in the relational database, beginning with the DEMO dataset. We first merged the quarters for the LAERS data and then proceeded with the FAERS data. During this process, we encountered and solved several conflicts:

1.  names of the variables were not constant, not only between LAERS and FAERS but also among different quarters within FAERS. We standardized them.

2.  not all the columns were compiled. We removed columns for which values were not provided, mainly because of privacy.

3.  some columns were duplicated in some quarters, for example due to a misspelling in the column name. We collapsed their values into a unique column.

4.  the missing of a data could be recorded as either "" or NA. We converted everything to NA.

To address these conflicts, we built a function and documented the details of merged and excluded variables, providing a step-by-step explanation of the script. Furthermore, we defined a variable with information about the quarter of year in which the drug was received by the FDA.

![](images/Screenshot%202023-07-18%20at%2012.56.37.png)

```{r eval=FALSE}
faers_list <- read.csv2("Clean Data/faers_list.csv")$x

unify_data <- function(files_list, namekey, column_subset,
                       duplicated_cols_x,duplicated_cols_y) {
  i <- 0
  foreach (f = files_list) %do%
    {name <- gsub(".TXT", ".rds", f, ignore.case = TRUE)
    print(name)
    x <- readRDS(name)
    x <- x[!is.na(names(x))]
    quart <- substr(name, nchar(name) - 7, nchar(name) - 4)
    x <- setDT(x)[, quarter := quart]
    names(x) <- namekey[names(x)]
    if (i > 0) {
      y <- rbindlist(list(y, x), fill = TRUE)
    } else {
      y <- x
    }
    i <- i + 1
    }
  if (sum(!is.na(duplicated_cols_x))>0){
    for (n in 1:length(duplicated_cols_x)){
      y[is.na(get(duplicated_cols_x[n])),
        (duplicated_cols_x[n]) := get(duplicated_cols_y[n])]
    }
  }
  removed_cols <- setdiff(colnames(y),column_subset)
  cols <- colnames(y)[colnames(y) %in% column_subset]
  y <- y[, ..cols]
  y[y == ""] <- NA
  y <- y %>% distinct()
  print(paste0("The following columns were lost in the cleaning: ",
               paste0(removed_cols,collapse = "; ")))
  return(y)
}
```

### DEMO

To ensure a cleaner and conflict-free database, the following steps were taken during the merging process for the DEMO dataset:

1.  Variables "IMAGE," "CONFID," and "DEATH_DT" were excluded from the dataset. This was done to adhere to privacy guidelines. In fact, these variables were not even included in the FAERS data.

2.  The FAERS variable "sex" was derived by combining the "sex" and "gndr_cod" variables.

3.  The FAERS variable "reporter date" was obtained by combining the "rept_dt" and " rept_dt" variables.

In particular we run the function unify_data with the parameters shown in the script below, and then saved the database as an RDS

```{r eval = FALSE}
DEMO <- unify_data(files_list = faers_list[str_detect(faers_list,
                                                      regex("demo",
                                                            ignore_case = T))],
                   namekey = c(ISR="primaryid",CASE="caseid",
                               FOLL_SEQ="caseversion",I_F_COD="i_f_cod",
                               EVENT_DT="event_dt",MFR_DT="mfr_dt",
                               FDA_DT="fda_dt",REPT_COD="rept_cod",
                               MFR_NUM="mfr_num",MFR_SNDR="mfr_sndr",
                               AGE="age",AGE_COD="age_cod",GNDR_COD="sex",
                               E_SUB="e_sub",WT="wt",WT_COD="wt_cod",
                               REPT_DT="rept_dt", OCCP_COD="occp_cod",
                               TO_MFR="to_mfr",
                               REPORTER_COUNTRY="reporter_country",
                               quarter="quarter",i_f_code="i_f_cod"),
                   column_subset = c("primaryid","caseid","caseversion",
                                     "i_f_cod","sex","age","age_cod","age_grp",
                                     "wt","wt_cod","reporter_country",
                                     "occr_country","event_dt","rept_dt",
                                     "mfr_dt","init_fda_dt","fda_dt","rept_cod",
                                     "occp_cod","mfr_num","mfr_sndr","to_mfr",
                                     "e_sub","quarter","auth_num","lit_ref"),
                   duplicated_cols_x = c("rept_dt" , "sex"),
                   duplicated_cols_y = c(" rept_dt", "gndr_cod"))
saveRDS(DEMO,"Clean Data/DEMO.rds")
rm(DEMO)
```

![](images/Diagram.drawio-4.svg)

![](images/Untitled-7.png)

![](images/Untitled-8.png)

![](images/Untitled-9.png)

![](images/Untitled-10.png)

### DRUG

To ensure a cleaner and conflict-free database, the following steps were taken during the merging process:

1.  The FAERS variable "lot num" was derived by combining the "lot num" and "lot_nbr" variables.

2.  LAERS and FAERS were merged into a new dataset DRUG (including only general information about which drugs and the suspect degree) and a new dataset DRUG_INFO (including details about doses, formulations, dechallenge, and routes). Both these datasets kept the primary (primaryid) and secondary key (drug_seq)

In particular we run the function unify_data with the parameters shown in the script below, and then saved the database as an RDS

```{r eval=FALSE}
DRUG <- unify_data(files_list = faers_list[str_detect(faers_list,regex("drug",ignore_case = T))],
                   namekey = c(ISR="primaryid",DRUG_SEQ="drug_seq",ROLE_COD="role_cod",
                     DRUGNAME="drugname",VAL_VBM="val_vbm",ROUTE="route",
                     DOSE_VBM="dose_vbm",DECHAL="dechal",
                     RECHAL="rechal",LOT_NUM="lot_num",NDA_NUM="nda_num",
                     EXP_DT="exp_dt"),
                   column_subset = c("primaryid","drug_seq","role_cod","drugname","prod_ai"),
                   duplicated_cols_x = NA,
                   duplicated_cols_y = NA)
saveRDS(DRUG,"Clean Data/DRUG.rds")
rm(DRUG)

DRUG_INFO <- unify_data(files_list = faers_list[str_detect(faers_list,regex("drug",ignore_case = T))],
                        namekey = c(ISR="primaryid",DRUG_SEQ="drug_seq",ROLE_COD="role_cod",
                          DRUGNAME="drugname",VAL_VBM="val_vbm",ROUTE="route",
                          DOSE_VBM="dose_vbm",DECHAL="dechal",
                          RECHAL="rechal",LOT_NUM="lot_num",NDA_NUM="nda_num",
                          EXP_DT="exp_dt"),
                        column_subset = c("primaryid","drug_seq","val_vbm","nda_num","lot_num",
                          "route","dose_form","dose_freq","exp_dt",
                          "dose_vbm","cum_dose_unit","cum_dose_chr","dose_amt",
                          "dose_unit","dechal","rechal"),
                        duplicated_cols_x = c("lot_num"),
                        duplicated_cols_y = c("lot_nbr"))
saveRDS(DRUG_INFO,"Clean Data/DRUG_INFO.rds")
rm(DRUG_INFO)
```

The information included in the DRUG database was stored in two different data frames for storage convenience. One with general information (in white) and one with details doses, lot and expiration dates (in blue).

![](images/Untitled-11.png)

![](images/Untitled-12.png)

![![](images/Untitled-14.png)](images/Untitled-13.png)

### INDI

To ensure a cleaner and conflict-free database, we run the function unify_data with the parameters shown in the script below, and then removed rows with no indication specified and saved the database as an RDS

```{r eval=FALSE}
INDÎ <- unify_data(faers_list[str_detect(faers_list,regex("indi",ignore_case = T))],
                   c(ISR="primaryid",DRUG_SEQ="drug_seq",
                     indi_drug_seq="drug_seq",INDI_PT="indi_pt"),
                   c("primaryid","drug_seq","indi_pt"),
                   NA,
                   NA)
INDÎ <- INDÎ[!is.na(indi_pt)]
saveRDS(INDÎ,"Clean Data/INDI.rds")
rm(INDÎ)
```

![](images/Untitled-15.png)

### OUTC

To ensure a cleaner and conflict-free database, we run the function unify_data with the parameters shown in the script below, and then removed rows with no outcome specified and saved the database as an RDS

```{r eval=FALSE}
OUTC <- unify_data(faers_list[str_detect(faers_list,regex("outc",ignore_case = T))],
                   c(ISR="primaryid",OUTC_COD="outc_cod"),
                   c("primaryid","outc_cod"),
                   c("outc_cod"),
                   c("outc_code"))
OUTC <- OUTC[!is.na(outc_cod)]
saveRDS(OUTC,"Clean Data/OUTC.rds")
rm(OUTC)
```

### REAC

To ensure a cleaner and conflict-free database, we run the function unify_data with the parameters shown in the script below, and then removed rows with no reaction specified and saved the database as an RDS.

```{r eval=FALSE}
REAC <- unify_data(faers_list[str_detect(faers_list,regex("reac",ignore_case = T))],
                   c(ISR="primaryid", PT="pt"),
                   c("primaryid","pt","drug_rec_act"),
                   NA,
                   NA)
REAC <- REAC[!is.na(pt)]
saveRDS(REAC,"Clean Data/REAC.rds")
rm(REAC)
```

### RPSR

To ensure a cleaner and conflict-free database, we run the function unify_data with the parameters shown in the script below, and saved the database as an RDS.

```{r eval=FALSE}
RPSR <- unify_data(faers_list[str_detect(faers_list,regex("rpsr",ignore_case = T))],
                   c(ISR="primaryid",RPSR_COD="rpsr_cod"),
                   c("primaryid", "rpsr_cod"),
                   NA,
                   NA)
saveRDS(RPSR,"Clean Data/RPSR.rds")
rm(RPSR)
```

### THER

To ensure a cleaner and conflict-free database, we run the function unify_data with the parameters shown in the script below, and saved the database as an RDS.

```{r eval = FALSE}
THER <- unify_data(faers_list[str_detect(faers_list,regex("ther",ignore_case = T))],
                   c(ISR="primaryid",dsg_drug_seq="drug_seq",
                     DRUG_SEQ="drug_seq",START_DT="start_dt",END_DT="end_dt",
                     DUR="dur",DUR_COD="dur_cod"),
                   c("primaryid","drug_seq","start_dt",
                     "end_dt","dur","dur_cod"),
                   NA,
                   NA)
saveRDS(THER,"Clean Data/THER.rds")
rm(THER)
```

## 3. Standardization

Standardizing the unstandardized FDA Adverse Event Reporting System (FAERS) holds paramount importance in ensuring data consistency and reliable analysis. The FAERS encompasses numerous fields, and while some are standardized based on established dictionaries, others lack such standardization. This inconsistency can impede data interpretation, hinder comparative studies, and hamper accurate identification of adverse events or drugs. Therefore, the pressing need for standardization arises to enhance data quality, facilitate meaningful insights, and enable robust pharmacovigilance efforts.

### MedDRA

```{r}
##MedDRA standardization-------------------------------------------------------
# Importing MedDRA
soc <- read.csv2("External Sources/Dictionaries/MedDRA/MedAscii/soc.asc",
                 sep = "$", header=F) %>% select(1:3)
colnames(soc) <- c("soc_cod","soc","def")
soc_hlgt <- read.csv2("External Sources/Dictionaries/MedDRA/MedAscii/soc_hlgt.asc",
                      sep = "$", header=F) %>% select(1:2)
colnames(soc_hlgt) <- c("soc_cod","hlgt_cod")
hlgt <- read.csv2("External Sources/Dictionaries/MedDRA/MedAscii/hlgt.asc",
                  sep = "$", header=F) %>% select(1:2)
colnames(hlgt) <- c("hlgt_cod","hlgt")
hlgt_hlt <- read.csv2("External Sources/Dictionaries/MedDRA/MedAscii/hlgt_hlt.asc",
                      sep = "$", header=F) %>% select(1:2)
colnames(hlgt_hlt) <- c("hlgt_cod","hlt_cod")
hlt <- read.csv2("External Sources/Dictionaries/MedDRA/MedAscii/hlt.asc",
                 sep = "$", header=F) %>% select(1:2)
colnames(hlt) <- c("hlt_cod","hlt")
hlt_pt <- read.csv2("External Sources/Dictionaries/MedDRA/MedAscii/hlt_pt.asc",
                    sep = "$", header=F)  %>% select(1:2)
colnames(hlt_pt) <- c("hlt_cod","pt_cod")
pts <- read.csv2("External Sources/Dictionaries/MedDRA/MedAscii/pt.asc",
                 sep = "$", header=F) %>% select(1:2,4)
colnames(pts) <- c("pt_cod","pt","primary_soc_cod")
llt <- read.csv2("External Sources/Dictionaries/MedDRA/MedAscii/llt.asc",
                 sep = "$", header=F) %>% select(1:3)
colnames(llt) <- c("llt_cod","llt","pt_cod")
# Merge the data
meddra <- setDT(merge(merge(merge(merge(merge(merge(merge(
  soc, soc_hlgt,all = TRUE),hlgt, all = TRUE),hlgt_hlt,all = TRUE),
  hlt, all = TRUE), hlt_pt, all = TRUE), pts, all = TRUE), llt,all=TRUE))
# Convert to lowercase
meddra[,(colnames(meddra)):=lapply(.SD, tolower),]
# Write the data to CSV files
write.csv2(distinct(meddra[,.(def,soc, hlgt,hlt,pt,llt)]),
           "External Sources/Dictionaries/MedDRA/meddra.csv")
write.csv2(distinct(meddra[soc_cod==primary_soc_cod][,.(def,soc, hlgt,hlt,pt)]),
           "External Sources/Dictionaries/MedDRA/meddra_primary.csv")


# Read PT file and extract unique lowercase PT values
pt_list <- unique(tolower(trimws(
  setDT(read.csv2("External Sources/Dictionaries/MedDRA/meddra.csv"))$pt)))
manual_fix_file <- "External Sources/Manual_fix/pt_fixed.csv"
standardize_PT <- function(data_file, pt_variable) {
  # Read data file
  data <- setDT(readRDS(data_file))
  
  # Extract PTs from data and calculate frequencies
  pt_freq <- data[, .(pt = tolower(trimws(get(pt_variable))))][
    !is.na(pt)][, .N, by = "pt"][order(-N)]
  
  # Check if PTs are standardized or not
  pt_freq[, standard_pt := ifelse(pt %in% pt_list, pt, NA)]
  pt_freq[, freq := round(N/sum(N) * 100, 2)]
  
  # Get unstandardized PTs
  not_pts <- pt_freq[is.na(standard_pt)][, .(pt, N, freq)]
  print(paste0("The portion of non standardized PTs at the beginning is ",
               round(sum(not_pts$N)*100/nrow(data[!is.na(get(pt_variable))]),3)))
  
  # Try to translate unstandardized PTs through LLTs
  llts <- left_join(not_pts, setDT(read.csv2("External Sources/Dictionaries/MedDRA/meddra.csv"))[
    , .(standard_pt = pt, pt = llt)])
  not_llts <- llts[is.na(standard_pt)] %>% select(-standard_pt)
  
  # If still untraslated, use manual integration
  pt_fixed <- setDT(read.csv2(manual_fix_file))[, .(pt, standard_pt)]
  manual <- left_join(not_llts, pt_fixed)[is.na(standard_pt),][, .(pt, standard_pt)]
  
  # Combine PTs from LLTs, manual integration, and already standardized PTs
  pt_fixed <- distinct(rbindlist(list(pt_fixed, manual, llts[!is.na(standard_pt), .(pt, standard_pt)])))
  unstandardized_pts <- pt_fixed[is.na(standard_pt)]
  # Write updated manual fix file
  write.csv2(pt_fixed, manual_fix_file)
  print(paste0(nrow(unstandardized_pts),
               " pts are not standardized using LLTs or previously proposed manual fix: ",
               paste0(unstandardized_pts$pt,collapse = "; "),
               ". Consider updating the pt_fixed.csv file."))
  pt_fixed <- setDT(read.csv2(manual_fix_file))[, .(pt_temp=pt, standard_pt)]
  # Update PTs in the data file
  data <- pt_fixed[data[, pt_temp := tolower(trimws(get(pt_variable)))], on = "pt_temp"][
    ,pt_temp := ifelse(is.na(standard_pt), pt_temp, standard_pt)] %>% select(-standard_pt)
  data <- data %>% select(-all_of(pt_variable))
  # Calculate the portion of standardized PTs
  standardized_percentage <- round(nrow(data[pt_temp %in% pt_list]) * 100 / nrow(data[!is.na(pt_temp)]), 3)
  print(paste0("The portion of standardized PTs at the end is ",
               standardized_percentage))
  setnames(data,old="pt_temp",new=pt_variable)
  
  # Return the standardized data and standardized percentage
  return(data)
}

Reac <- standardize_PT("Clean Data/Reac.rds","pt")
#consider updating the pt_fixed file
saveRDS(Reac,"Clean Data/Reac.rds")
Reac <- standardize_PT("Clean Data/Reac.rds","drug_rec_act")
#consider updating the pt_fixed file
saveRDS(Reac,"Clean Data/Reac.rds")
Indi <- standardize_PT("Clean Data/Indi.rds","indi_pt")
#consider updating the pt_fixed file
saveRDS(Indi,"Clean Data/Indi.rds")
```

### Drug

## 6. Remove deleted (nullified) reports

## 7. Flattening of case versions

## 8. Deduplication
